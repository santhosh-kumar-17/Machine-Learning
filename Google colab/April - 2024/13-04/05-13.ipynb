{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'TimeseriesDataset' from 'darts.utils.data' (c:\\Users\\santh\\anaconda3\\Lib\\site-packages\\darts\\utils\\data\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdarts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TimeSeries\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdarts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RNNModel\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdarts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TimeseriesDataset\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdarts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mape\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdarts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtimeseries_generation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime_attribute_timeseries\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'TimeseriesDataset' from 'darts.utils.data' (c:\\Users\\santh\\anaconda3\\Lib\\site-packages\\darts\\utils\\data\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from darts import TimeSeries\n",
    "from darts.models import RNNModel\n",
    "from darts.utils.data import TimeseriesDataset\n",
    "from darts.metrics import mape\n",
    "from darts.utils.timeseries_generation import datetime_attribute_timeseries\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('nifty_dataPEE.csv')\n",
    "series = TimeSeries.from_dataframe(df, 'lasttradetime', ['close'])\n",
    "\n",
    "# Split data\n",
    "train, val = series.split_before(pd.Timestamp('2024-01-01'))\n",
    "\n",
    "# Normalize data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "train_scaled = scaler.fit_transform(train)\n",
    "val_scaled = scaler.transform(val)\n",
    "\n",
    "# Define model parameters\n",
    "lookback_window = 5\n",
    "batch_size = 30\n",
    "units = 100\n",
    "epochs = 20\n",
    "\n",
    "# Create dataset\n",
    "train_dataset = TimeseriesDataset.from_series(train_scaled, lookback_window + 1)\n",
    "val_dataset = TimeseriesDataset.from_series(val_scaled, lookback_window + 1)\n",
    "\n",
    "# Create and train the model\n",
    "model = RNNModel(\n",
    "    model='LSTM',\n",
    "    input_chunk_length=lookback_window,\n",
    "    output_chunk_length=1,\n",
    "    hidden_size=units,\n",
    "    n_rnn_layers=1,\n",
    "    batch_size=batch_size,\n",
    "    n_epochs=epochs,\n",
    "    optimizer_kwargs={'lr': 1e-3},\n",
    "    model_name='LSTM_nifty',\n",
    "    log_tensorboard=True,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "model.fit(train_dataset, val_series=val_scaled, verbose=True)\n",
    "\n",
    "# Make forecasts\n",
    "forecast = model.predict(n=len(val))\n",
    "\n",
    "# Inverse scaling\n",
    "forecast = scaler.inverse_transform(forecast)\n",
    "\n",
    "# Print max and min forecasted close prices\n",
    "print(forecast['close'].max(), forecast['close'].min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ValueError: The time index of the provided DataArray is missing the freq attribute, and the frequency could not be directly inferred. This probably comes from inconsistent date frequencies with missing dates. If you know the actual frequency, try setting `fill_missing_dates=True, freq=actual_frequency`. If not, try setting `fill_missing_dates=True, freq=None` to see if a frequency can be inferred.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The time index of the provided DataArray is missing the freq attribute, and the frequency could not be directly inferred. This probably comes from inconsistent date frequencies with missing dates. If you know the actual frequency, try setting `fill_missing_dates=True, freq=actual_frequency`. If not, try setting `fill_missing_dates=True, freq=None` to see if a frequency can be inferred.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Load data\u001b[39;00m\n\u001b[0;32m      7\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnifty_dataPEE.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m series \u001b[38;5;241m=\u001b[39m TimeSeries\u001b[38;5;241m.\u001b[39mfrom_dataframe(df, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlasttradetime\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Split data\u001b[39;00m\n\u001b[0;32m     11\u001b[0m train, val \u001b[38;5;241m=\u001b[39m series\u001b[38;5;241m.\u001b[39msplit_before(pd\u001b[38;5;241m.\u001b[39mTimestamp(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2024-01-01\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\santh\\anaconda3\\Lib\\site-packages\\darts\\timeseries.py:744\u001b[0m, in \u001b[0;36mTimeSeries.from_dataframe\u001b[1;34m(cls, df, time_col, value_cols, fill_missing_dates, freq, fillna_value, static_covariates, hierarchy)\u001b[0m\n\u001b[0;32m    735\u001b[0m     series_df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    737\u001b[0m xa \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mDataArray(\n\u001b[0;32m    738\u001b[0m     series_df\u001b[38;5;241m.\u001b[39mvalues[:, :, np\u001b[38;5;241m.\u001b[39mnewaxis],\n\u001b[0;32m    739\u001b[0m     dims\u001b[38;5;241m=\u001b[39m(time_index\u001b[38;5;241m.\u001b[39mname,) \u001b[38;5;241m+\u001b[39m DIMS[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:],\n\u001b[0;32m    740\u001b[0m     coords\u001b[38;5;241m=\u001b[39m{time_index\u001b[38;5;241m.\u001b[39mname: time_index, DIMS[\u001b[38;5;241m1\u001b[39m]: series_df\u001b[38;5;241m.\u001b[39mcolumns},\n\u001b[0;32m    741\u001b[0m     attrs\u001b[38;5;241m=\u001b[39m{STATIC_COV_TAG: static_covariates, HIERARCHY_TAG: hierarchy},\n\u001b[0;32m    742\u001b[0m )\n\u001b[1;32m--> 744\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_xarray(\n\u001b[0;32m    745\u001b[0m     xa\u001b[38;5;241m=\u001b[39mxa,\n\u001b[0;32m    746\u001b[0m     fill_missing_dates\u001b[38;5;241m=\u001b[39mfill_missing_dates,\n\u001b[0;32m    747\u001b[0m     freq\u001b[38;5;241m=\u001b[39mfreq,\n\u001b[0;32m    748\u001b[0m     fillna_value\u001b[38;5;241m=\u001b[39mfillna_value,\n\u001b[0;32m    749\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\santh\\anaconda3\\Lib\\site-packages\\darts\\timeseries.py:471\u001b[0m, in \u001b[0;36mTimeSeries.from_xarray\u001b[1;34m(cls, xa, fill_missing_dates, freq, fillna_value)\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;66;03m# We cast the array to float\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(xa_\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;129;01mor\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(\n\u001b[0;32m    469\u001b[0m     xa_\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mfloat64\n\u001b[0;32m    470\u001b[0m ):\n\u001b[1;32m--> 471\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(xa_)\n\u001b[0;32m    472\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(xa_\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64))\n",
      "File \u001b[1;32mc:\\Users\\santh\\anaconda3\\Lib\\site-packages\\darts\\timeseries.py:189\u001b[0m, in \u001b[0;36mTimeSeries.__init__\u001b[1;34m(self, xa, copy)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_freq \u001b[38;5;241m=\u001b[39m to_offset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_xa\u001b[38;5;241m.\u001b[39mget_index(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time_dim)\u001b[38;5;241m.\u001b[39minferred_freq)\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_freq \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 189\u001b[0m     raise_log(\n\u001b[0;32m    190\u001b[0m         \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    191\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe time index of the provided DataArray is missing the freq attribute, and the frequency \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    192\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not be directly inferred. This probably comes from inconsistent date frequencies with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    193\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmissing dates. If you know the actual frequency, try setting `fill_missing_dates=True, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    194\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfreq=actual_frequency`. If not, try setting `fill_missing_dates=True, freq=None` to see if a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    195\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency can be inferred.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    196\u001b[0m         ),\n\u001b[0;32m    197\u001b[0m         logger,\n\u001b[0;32m    198\u001b[0m     )\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_freq_str: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_freq\u001b[38;5;241m.\u001b[39mfreqstr\n\u001b[0;32m    202\u001b[0m \u001b[38;5;66;03m# reset freq inside the xarray index (see bug of sortby() above).\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\santh\\anaconda3\\Lib\\site-packages\\darts\\logging.py:132\u001b[0m, in \u001b[0;36mraise_log\u001b[1;34m(exception, logger)\u001b[0m\n\u001b[0;32m    129\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(exception)\n\u001b[0;32m    130\u001b[0m logger\u001b[38;5;241m.\u001b[39merror(exception_type \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m message)\n\u001b[1;32m--> 132\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[1;31mValueError\u001b[0m: The time index of the provided DataArray is missing the freq attribute, and the frequency could not be directly inferred. This probably comes from inconsistent date frequencies with missing dates. If you know the actual frequency, try setting `fill_missing_dates=True, freq=actual_frequency`. If not, try setting `fill_missing_dates=True, freq=None` to see if a frequency can be inferred."
     ]
    }
   ],
   "source": [
    "from darts import TimeSeries\n",
    "from darts.models import RNNModel\n",
    "from darts.metrics import mape\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('nifty_dataPEE.csv')\n",
    "series = TimeSeries.from_dataframe(df, 'lasttradetime', ['close'])\n",
    "\n",
    "# Split data\n",
    "train, val = series.split_before(pd.Timestamp('2024-01-01'))\n",
    "\n",
    "# Normalize data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "train_scaled = scaler.fit_transform(train)\n",
    "val_scaled = scaler.transform(val)\n",
    "\n",
    "# Define model parameters\n",
    "lookback_window = 5\n",
    "batch_size = 30\n",
    "units = 100\n",
    "epochs = 20\n",
    "\n",
    "# Convert time series data into sequences\n",
    "def create_sequences(data, lookback_window):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - lookback_window - 1):\n",
    "        X.append(data[i:(i + lookback_window)])\n",
    "        y.append(data[i + lookback_window])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_train, y_train = create_sequences(train_scaled, lookback_window)\n",
    "X_val, y_val = create_sequences(val_scaled, lookback_window)\n",
    "\n",
    "# Create and train the model\n",
    "model = RNNModel(\n",
    "    model='LSTM',\n",
    "    input_chunk_length=lookback_window,\n",
    "    output_chunk_length=1,\n",
    "    hidden_size=units,\n",
    "    n_rnn_layers=1,\n",
    "    batch_size=batch_size,\n",
    "    n_epochs=epochs,\n",
    "    optimizer_kwargs={'lr': 1e-3},\n",
    "    model_name='LSTM_nifty',\n",
    "    log_tensorboard=True,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, verbose=True, val_series=X_val, val_targets=y_val)\n",
    "\n",
    "# Make forecasts\n",
    "forecast = model.predict(n=len(val_scaled))\n",
    "\n",
    "# Inverse scaling\n",
    "forecast = scaler.inverse_transform(forecast)\n",
    "\n",
    "# Print max and min forecasted close prices\n",
    "print(forecast['close'].max(), forecast['close'].min())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
